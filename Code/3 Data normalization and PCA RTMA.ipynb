{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c439f726",
   "metadata": {},
   "source": [
    "## Data set preparation for ML model development - PCA based variable pool with RTMA data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c8af6",
   "metadata": {},
   "source": [
    "### Set up/check environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5799981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check environment\n",
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00052d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "import glob2\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import LabelBinarizer as lb\n",
    "\n",
    "# set the number of maximum displayed rows for printed dataframes to 1000\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot raw data\n",
    "\n",
    "PCA_df = pd.read_csv('')\n",
    "\n",
    "# including 'row_shading instead of canopy closure and row spacing'\n",
    "row_shading = PCA_df['canopy_avg'] * PCA_df['spacing (m)']\n",
    "insert_index = PCA_df.columns.get_loc('canopy_avg') + 1  # Insert after col1\n",
    "PCA_df.insert(insert_index, 'row_shading', row_shading)\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set(font_scale=0.5) \n",
    "ax = sns.catplot(data=PCA_df, kind = 'bar')\n",
    "ax.set_xticklabels(rotation=90, ha=\"right\")\n",
    "ax.set(title = 'Raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7671a",
   "metadata": {},
   "source": [
    "#### Max absolute rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b799b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# copy the data - only the numerical data\n",
    "dt_max_scaled = PCA_df.iloc[:, 7:]\n",
    "\n",
    "# apply normalization techniques\n",
    "for column in dt_max_scaled.columns:\n",
    "    dt_max_scaled[column] = dt_max_scaled[column]  / dt_max_scaled[column].abs().max()\n",
    "    \n",
    "# plot normalized data\n",
    "sns.set_theme()\n",
    "sns.set(font_scale=0.5) \n",
    "ax = sns.catplot(data=dt_max_scaled, kind = 'bar')\n",
    "ax.set_xticklabels(rotation=90, ha=\"right\")\n",
    "ax.set(title = 'Max absolute rescaled data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695cd51c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply PCA - max absolute\n",
    "pca = PCA(n_components=None) # no limit to number of PCAS\n",
    "pca.fit(dt_max_scaled) # performing PCA\n",
    "\n",
    "# retrieve the eigenvalues\n",
    "#print(\"Eigenvalues:\")\n",
    "#print(pca.explained_variance_)\n",
    "#print()\n",
    "\n",
    "# return explained variances\n",
    "#print(\"Variances (Percentage):\")\n",
    "#print(pca.explained_variance_ratio_ * 100)\n",
    "#print()\n",
    "\n",
    "# plot the scree plot\n",
    "plt.figure(figsize=(3.25, 3.25), dpi=1200)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_ * 100))\n",
    "plt.xlabel(\"Number of components (Dimensions)\")\n",
    "plt.ylabel(\"Explained variance (%)\")\n",
    "plt.title('Max absolute rescaling - RTMA\\nNumber of PCs needed to explain 90% of variance: 5')\n",
    "\n",
    "# return the number of PCs needed to explain 95% of the variance\n",
    "pca = PCA(0.90) # set threshold for explained variance to 90%\n",
    "principalComponents = pca.fit_transform(dt_max_scaled) # perform PCA\n",
    "print(\"number of PCs needed to explain 90% of variance:\",  np.shape(principalComponents)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62944936",
   "metadata": {},
   "source": [
    "### Perform PCA to achieve 0.9 explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictating thresold for number of PCs\n",
    "pca = PCA(0.90) \n",
    "# calculate principal components - using max absolute rescaled values\n",
    "principalComponents = pca.fit_transform(dt_max_scaled) \n",
    "# creating column names for principal components\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2', \n",
    "                                                                  'principal component 3', 'principal component 4',\n",
    "                                                                  'principal component 5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb64ec",
   "metadata": {},
   "source": [
    "### Merge PCA data and target data for training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging principal components with targets (binary classification for each data point)\n",
    "# changing the array of solutions to a single column data frame\n",
    "dt_sol = pd.DataFrame(PCA_df.target) \n",
    "\n",
    "# merging predictor data (principal components and withheld categorical predictors) with the solutions   \n",
    "pc_df = pd.merge(dt_sol, principalDf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a8e78",
   "metadata": {},
   "source": [
    "### Data splitting (original - no stratification)\n",
    "* Training: 80%, testing 20%  \n",
    "* Stratification by apothecia threshold binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea96e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into x and y\n",
    "xdat = pd.merge(PCA_df.iloc[:, 3], pc_df.loc[:, pc_df.columns != 'target' ], left_index = True, right_index = True) \n",
    "ydat = pd.DataFrame(pc_df.loc[:, 'target'])\n",
    "\n",
    "# using binary encoding to transform categorical soil type\n",
    "xdat['soil type'].replace(['sand', 'loamy sand', 'loam'], [0, 1, 2], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeea86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratifying by dt_sol\n",
    "x_train, x_test, y_train, y_test = train_test_split(xdat, ydat, test_size=0.20, random_state=42, stratify=dt_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a2067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking that indexes for data split between x and y match for training and test\n",
    "print('x training indexes:', x_train.index)\n",
    "print('y training indexes:', y_train.index)\n",
    "\n",
    "print('x testing indexes:', x_test.index)\n",
    "print('y testing indexes:', y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking stratification (equal proportions of positive solutions (target = 1) between train and test)\n",
    "print(sum(y_train['target'])/len(y_train))\n",
    "print(sum(y_test['target'])/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e754ecb",
   "metadata": {},
   "source": [
    "### PCA - data load out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b484ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv('', index=False, header=True)\n",
    "y_train.to_csv('', index=False, header=True)\n",
    "x_test.to_csv('', index=False, header=True)\n",
    "y_test.to_csv('', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
